# ----------------------------------------------------------------------------------------
#
#   Jupyterlab setup with NVIDIA GPU support
#
#   Jupyter Lab - http://localhost:8888
#   Tensorboard - http://localhost:6006
#
# ----------------------------------------------------------------------------------------
services:
  # run jupyterlab on a local port 8888
  # without any authentication
  jupyterlab:
    container_name: lab-gpu
    hostname: lab-gpu
    image: stellars/stellars-jupyterlab-ds:latest
    build:
      context: build
      dockerfile: Dockerfile
    command: /start-jupyterlab.sh
    environment:
      - CONDA_DEFAULT_ENV=base # choices are: base, tensorflow, torch
      - GPU_SUPPORT_ENABLED=1 # system support for gpu
      - JUPYTERLAB_SERVER_IP=*
      - JUPYTERLAB_SERVER_TOKEN=
      - TF_CPP_MIN_LOG_LEVEL=3 # reduce tensorflow logging level
      - CUDA_VISIBLE_DEVICES=  # put 0,1,2 and other identifiers of gpu-s visible to CUDA
    ports:
      - 8888:8888 # jupyterlab
      - 8000:8000 # jupyterhub
      - 8001:8001 # jupyterhub proxy
      - 6006:6006 # tensorboard
      - 5000:5000 # mlflow
    networks:
      - frontend
    volumes:
      - home:/home                    # jupyterlab user directory persistence
      - workspace:/home/lab/workspace # user projects workspace volume persistence
      - certs:/mnt/certs              # persistent certificate store for ssl
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  workspace:
  certs:
  home:

networks:
  frontend:
    driver: bridge


# EOF

